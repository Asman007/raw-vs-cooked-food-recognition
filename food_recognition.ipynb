{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw vs Cooked Food Recognition - Interactive Notebook\n",
    "\n",
    "This notebook provides an interactive environment for training and testing the food classification model.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Data Exploration](#exploration)\n",
    "3. [Model Training](#training)\n",
    "4. [Model Evaluation](#evaluation)\n",
    "5. [Predictions](#predictions)\n",
    "6. [Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration <a name=\"exploration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/validation'\n",
    "\n",
    "def count_images(directory):\n",
    "    \"\"\"Count images in directory\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    return len([f for f in os.listdir(directory) \n",
    "               if os.path.splitext(f.lower())[1] in image_extensions])\n",
    "\n",
    "# Count images\n",
    "train_raw = count_images(os.path.join(train_dir, 'raw'))\n",
    "train_cooked = count_images(os.path.join(train_dir, 'cooked'))\n",
    "val_raw = count_images(os.path.join(val_dir, 'raw'))\n",
    "val_cooked = count_images(os.path.join(val_dir, 'cooked'))\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  Raw: {train_raw}\")\n",
    "print(f\"  Cooked: {train_cooked}\")\n",
    "print(f\"  Total: {train_raw + train_cooked}\")\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  Raw: {val_raw}\")\n",
    "print(f\"  Cooked: {val_cooked}\")\n",
    "print(f\"  Total: {val_raw + val_cooked}\")\n",
    "\n",
    "# Visualize distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Training set\n",
    "ax1.bar(['Raw', 'Cooked'], [train_raw, train_cooked], color=['#95E1D3', '#FF6B6B'])\n",
    "ax1.set_title('Training Set Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Images')\n",
    "for i, v in enumerate([train_raw, train_cooked]):\n",
    "    ax1.text(i, v + 5, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Validation set\n",
    "ax2.bar(['Raw', 'Cooked'], [val_raw, val_cooked], color=['#95E1D3', '#FF6B6B'])\n",
    "ax2.set_title('Validation Set Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Number of Images')\n",
    "for i, v in enumerate([val_raw, val_cooked]):\n",
    "    ax2.text(i, v + 1, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def show_sample_images(directory, n_samples=5):\n",
    "    \"\"\"Display sample images from each category\"\"\"\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(15, 6))\n",
    "    \n",
    "    for row, category in enumerate(['raw', 'cooked']):\n",
    "        cat_dir = os.path.join(directory, category)\n",
    "        if os.path.exists(cat_dir):\n",
    "            images = [f for f in os.listdir(cat_dir) \n",
    "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            for col in range(min(n_samples, len(images))):\n",
    "                img_path = os.path.join(cat_dir, images[col])\n",
    "                img = Image.open(img_path)\n",
    "                axes[row, col].imshow(img)\n",
    "                axes[row, col].axis('off')\n",
    "                if col == 0:\n",
    "                    axes[row, col].set_title(category.capitalize(), \n",
    "                                           fontsize=12, fontweight='bold', loc='left')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Dataset', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if train_raw > 0 and train_cooked > 0:\n",
    "    show_sample_images(train_dir, n_samples=5)\n",
    "else:\n",
    "    print(\"No images found in training directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training <a name=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented images\n",
    "def visualize_augmentation(generator):\n",
    "    \"\"\"Show examples of data augmentation\"\"\"\n",
    "    batch = next(generator)\n",
    "    images = batch[0][:9]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_augmentation(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'notebook_best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation <a name=\"evaluation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('notebook_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy, val_precision, val_recall = model.evaluate(val_generator)\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Loss: {val_loss:.4f}\")\n",
    "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall: {val_recall:.4f}\")\n",
    "print(f\"F1-Score: {2 * (val_precision * val_recall) / (val_precision + val_recall):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "val_generator.reset()\n",
    "predictions = model.predict(val_generator, steps=len(val_generator))\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "true_classes = val_generator.classes\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Cooked', 'Raw'],\n",
    "            yticklabels=['Cooked', 'Raw'])\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(true_classes, predicted_classes, \n",
    "                          target_names=['Cooked', 'Raw']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions <a name=\"predictions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('notebook_food_classifier.h5')\n",
    "print(\"✓ Model saved as 'notebook_food_classifier.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict single image\n",
    "def predict_image(image_path, model):\n",
    "    \"\"\"Predict if food is raw or cooked\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "    \n",
    "    if prediction > 0.5:\n",
    "        label = 'Raw'\n",
    "        confidence = prediction * 100\n",
    "    else:\n",
    "        label = 'Cooked'\n",
    "        confidence = (1 - prediction) * 100\n",
    "    \n",
    "    return {\n",
    "        'label': label,\n",
    "        'confidence': confidence,\n",
    "        'raw_score': prediction * 100,\n",
    "        'cooked_score': (1 - prediction) * 100,\n",
    "        'image': img\n",
    "    }\n",
    "\n",
    "# Test prediction (replace with your image path)\n",
    "# result = predict_image('path/to/your/image.jpg', model)\n",
    "# print(f\"Prediction: {result['label']} ({result['confidence']:.2f}% confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization <a name=\"visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on validation set\n",
    "val_generator.reset()\n",
    "batch = next(val_generator)\n",
    "images = batch[0][:9]\n",
    "true_labels = batch[1][:9]\n",
    "\n",
    "predictions = model.predict(images, verbose=0)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "class_names = ['Cooked', 'Raw']\n",
    "\n",
    "for i, (img, true_label, pred) in enumerate(zip(images, true_labels, predictions)):\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    pred_class = int(pred[0] > 0.5)\n",
    "    pred_label = class_names[pred_class]\n",
    "    true_label_name = class_names[int(true_label)]\n",
    "    confidence = pred[0] * 100 if pred_class == 1 else (1 - pred[0]) * 100\n",
    "    \n",
    "    color = 'green' if pred_class == int(true_label) else 'red'\n",
    "    \n",
    "    axes[i].set_title(\n",
    "        f\"True: {true_label_name}\\nPred: {pred_label} ({confidence:.1f}%)\",\n",
    "        color=color,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.suptitle('Predictions on Validation Set', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('validation_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "final_metrics = {\n",
    "    'Metric': ['Training Accuracy', 'Validation Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Score': [\n",
    "        f\"{history.history['accuracy'][-1]:.4f}\",\n",
    "        f\"{val_accuracy:.4f}\",\n",
    "        f\"{val_precision:.4f}\",\n",
    "        f\"{val_recall:.4f}\",\n",
    "        f\"{2 * (val_precision * val_recall) / (val_precision + val_recall):.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(final_metrics)\n",
    "print(\"\\nFinal Model Metrics:\")\n",
    "print(\"=\"*50)\n",
    "print(df_metrics.to_string(index=False))\n",
    "\n",
    "# Save metrics\n",
    "df_metrics.to_csv('model_metrics.csv', index=False)\n",
    "print(\"\\n✓ Metrics saved to 'model_metrics.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Your model is now trained and ready to use! You can:\n",
    "\n",
    "1. Use the saved model (`notebook_food_classifier.h5`) for predictions\n",
    "2. Load it in the web app or prediction scripts\n",
    "3. Continue experimenting with different architectures\n",
    "4. Fine-tune hyperparameters for better performance\n",
    "\n",
    "**Next Steps:**\n",
    "- Try transfer learning with pre-trained models (VGG16, ResNet, EfficientNet)\n",
    "- Experiment with different data augmentation techniques\n",
    "- Collect more diverse training data\n",
    "- Test on real-world images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
